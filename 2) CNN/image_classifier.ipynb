{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4439e2",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4846048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    # Metodo costruttore / Schema della rete neurale\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(8* 56 * 56, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool(F.relu(self.conv1(x)))\n",
    "        out = self.pool(F.relu(self.conv2(out)))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d20a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), # Trasformiamo l'immagine in un tensore\n",
    "])\n",
    "\n",
    "# Peschiamo i dati di training\n",
    "dataset = datasets.ImageFolder(root='dataset', transform=transform)\n",
    "print(dataset.class_to_idx)\n",
    "\n",
    "# Suddividiamo il dataset in training e validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71844da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6860524713993073\n",
      "Epoch 1, Loss: 0.6737722635269165\n",
      "Epoch 2, Loss: 0.647117656469345\n",
      "Epoch 3, Loss: 0.6017773270606994\n",
      "Epoch 4, Loss: 0.5721716940402984\n",
      "Epoch 5, Loss: 0.5076314270496368\n",
      "Epoch 6, Loss: 0.4637900412082672\n",
      "Epoch 7, Loss: 0.41112600862979887\n",
      "Epoch 8, Loss: 0.3859466940164566\n",
      "Epoch 9, Loss: 0.2936780959367752\n",
      "Epoch 10, Loss: 0.24542222470045089\n",
      "Epoch 11, Loss: 0.20702120363712312\n",
      "Epoch 12, Loss: 0.14328788593411446\n",
      "Epoch 13, Loss: 0.13495455980300902\n",
      "Epoch 14, Loss: 0.08506143242120742\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(15):\n",
    "    running_loss = 0.0 # Rappresenta la loss del singolo batch\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(images) # Prima volta in cui passiamo le immagini nella rete\n",
    "        loss = loss_fn(outputs, labels) # Calcoliamo la loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader) # Loss media su tutti i batch\n",
    "    print(f\"Epoch {epoch}, Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d9aed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9958, -4.2078]], device='cuda:0')\n",
      "tensor([[99.4533,  0.5467]], device='cuda:0')%\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('dataset\\\\cats\\\\cat (3).jpg').convert('RGB')\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor)\n",
    "    probs = torch.softmax(output, dim=1)    \n",
    "print(output)\n",
    "print(f\"{probs*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4089510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"C:\\\\Users\\\\rdarc\\\\Desktop\\\\Reti Neurali\\\\Codice\\\\image_classifier.pth\", weights_only=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
